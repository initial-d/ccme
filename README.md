# ä¿¡æ¯å¤æ‚åº¦ä¸å¸‚åœºæ•ˆç‡ç ”ç©¶é¡¹ç›®

## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å®ç°äº†è®ºæ–‡ã€ŠComputational Complexity and Market Efficiency: A Machine Learning Approach to Information Processing in Financial Marketsã€‹ä¸­æå‡ºçš„æ ¸å¿ƒç®—æ³•ã€‚è¯¥ç ”ç©¶æ¢ç´¢äº†ä¿¡æ¯å¤æ‚åº¦å¯¹é‡‘èå¸‚åœºä»·æ ¼å‘ç°æ•ˆç‡çš„å½±å“ï¼Œå¹¶å¼€å‘äº†å¤æ‚åº¦æ„ŸçŸ¥çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚

## ğŸš€ ä¸»è¦ç‰¹æ€§

- **ä¿¡æ¯å¤æ‚åº¦æµ‹é‡**ï¼šKolmogorovå¤æ‚åº¦ã€è®¡ç®—å¤æ‚åº¦å’Œé€»è¾‘æ·±åº¦çš„å¤šç»´åº¦è¯„ä¼°
- **å¤æ‚åº¦æ„ŸçŸ¥ç¥ç»ç½‘ç»œ**ï¼šèå…¥è®¡ç®—å¤æ‚åº¦çº¦æŸçš„æ·±åº¦å­¦ä¹ æ¨¡å‹
- **å¯è§£é‡ŠAIæ¡†æ¶**ï¼šSHAPåˆ†æå’Œå¤æ‚åº¦åˆ†è§£
- **ç®—æ³•äº¤æ˜“æ£€æµ‹**ï¼šåŸºäºè®¢å•æµç‰¹å¾çš„ç®—æ³•äº¤æ˜“è¯†åˆ«
- **æ•°æ®å¤„ç†ç®¡é“**ï¼šå®Œæ•´çš„æ•°æ®æ¸…æ´—å’Œæ ·æœ¬æ„å»ºæµç¨‹
- **ç»Ÿè®¡åˆ†æå·¥å…·**ï¼šå›å½’åˆ†æã€ç¨³å¥æ€§æ£€éªŒå’Œå¯è§†åŒ–

## ğŸ“ é¡¹ç›®ç»“æ„

```
ccme/src/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ kolmogorov_calculator.py          # Kolmogorovå¤æ‚åº¦è®¡ç®—
â”œâ”€â”€ computational_analyzer.py         # è®¡ç®—å¤æ‚åº¦åˆ†æ
â”œâ”€â”€ complexity_aware_model.py         # å¤æ‚åº¦æ„ŸçŸ¥ç¥ç»ç½‘ç»œ
â”œâ”€â”€ explainable_ai.py                 # å¯è§£é‡ŠAIæ¡†æ¶
â”œâ”€â”€ algorithmic_trading_detector.py   # ç®—æ³•äº¤æ˜“æ£€æµ‹
â”œâ”€â”€ data_processing.py                # æ•°æ®å¤„ç†å’Œè´¨é‡æ§åˆ¶
â””â”€â”€ statistical_analysis.py           # ç»Ÿè®¡åˆ†æå’Œå¯è§†åŒ–
```

## ğŸ› ï¸ å®‰è£…æŒ‡å—

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 1.9+

### å®‰è£…æ­¥éª¤

1. **å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®æ–‡ä»¶**

2. **å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt
```

### ä¾èµ–åŒ…åˆ—è¡¨ (requirements.txt)

```txt
torch>=1.9.0
numpy>=1.21.0
pandas>=1.3.0
scipy>=1.7.0
scikit-learn>=1.0.0
matplotlib>=3.4.0
seaborn>=0.11.0
plotly>=5.0.0
shap>=0.40.0
networkx>=2.6.0
zstandard>=0.15.0
brotli>=1.0.9
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä¿¡æ¯å¤æ‚åº¦è®¡ç®—

```python
from kolmogorov_calculator import KolmogorovComplexityCalculator
from computational_analyzer import ComputationalComplexityAnalyzer, LogicalDepthEstimator

# è®¡ç®—Kolmogorovå¤æ‚åº¦
calculator = KolmogorovComplexityCalculator()
result = calculator.theoretical_kolmogorov("å¤æ‚çš„é‡‘èä¿¡æ¯æ–‡æœ¬...")
print(f"Kolmogorovå¤æ‚åº¦: {result.kolmogorov_approx:.4f}")

# è®¡ç®—è®¡ç®—å¤æ‚åº¦
comp_analyzer = ComputationalComplexityAnalyzer()
comp_complexity = comp_analyzer.measure_computational_complexity("è´¢åŠ¡æ¯”ç‡åˆ†ææ•°æ®")
print(f"è®¡ç®—å¤æ‚åº¦: {comp_complexity}")

# ä¼°è®¡é€»è¾‘æ·±åº¦
depth_estimator = LogicalDepthEstimator()
logical_depth = depth_estimator.estimate_logical_depth("å¤šå› å­æ¨¡å‹åˆ†æ")
print(f"é€»è¾‘æ·±åº¦: {logical_depth}")
```

### 2. å¤æ‚åº¦æ„ŸçŸ¥ç¥ç»ç½‘ç»œ

```python
import torch
from complexity_aware_model import ComplexityAwareModel

# åˆ›å»ºæ¨¡å‹
model = ComplexityAwareModel(vocab_size=10000, d_model=256)

# å‡†å¤‡æ•°æ®
batch_size = 8
data = {
    'text_ids': torch.randint(0, 1000, (batch_size, 20)),
    'numerical_data': torch.randn(batch_size, 5),
    'kolmogorov': torch.rand(batch_size),
    'computational': torch.randint(1, 100, (batch_size,)).float(),
    'logical_depth': torch.randint(1, 10, (batch_size,)).float()
}

# æ¨¡å‹é¢„æµ‹
outputs = model(**data)
print(f"é¢„æµ‹çš„ä»·æ ¼å‘ç°é€Ÿåº¦: {outputs['discovery_speed'].mean():.2f} å°æ—¶")
print(f"å‘ç°æ•ˆç‡: {outputs['discovery_efficiency'].mean():.2%}")
```

### 3. æ¨¡å‹è§£é‡Š

```python
from explainable_ai import ModelExplainer

# åˆ›å»ºè§£é‡Šå™¨
explainer = ModelExplainer(model, ['kolmogorov', 'computational', 'logical_depth'])

# ç”Ÿæˆè§£é‡Š
explanations = explainer.explain_prediction(data)
report = explainer.generate_explanation_report(data)
print(report)

# å¯è§†åŒ–å¤æ‚åº¦æ•ˆåº”
from explainable_ai import VisualizationTools
VisualizationTools.plot_complexity_effects(
    explanations['complexity_decomposition']['individual_effects'],
    explanations['complexity_decomposition']['contributions']
)
```

### 4. ç®—æ³•äº¤æ˜“æ£€æµ‹

```python
from algorithmic_trading_detector import AlgorithmicTradingDetector, SyntheticDataGenerator

# ç”Ÿæˆæµ‹è¯•æ•°æ®
data_generator = SyntheticDataGenerator()
training_data = {}
labels = {}

# ç”Ÿæˆäººå·¥å’Œç®—æ³•äº¤æ˜“æ•°æ®
for i in range(50):
    training_data[f"human_{i}"] = data_generator.generate_human_trading_session()
    labels[f"human_{i}"] = 0
    
    training_data[f"algo_{i}"] = data_generator.generate_algorithmic_trading_session()
    labels[f"algo_{i}"] = 1

# è®­ç»ƒæ£€æµ‹å™¨
detector = AlgorithmicTradingDetector()
results = detector.train(training_data, labels)
print(f"äº¤å‰éªŒè¯AUC: {results['cv_auc_mean']:.4f}")

# é¢„æµ‹æ–°æ•°æ®
test_data = {
    'test_session': data_generator.generate_human_trading_session()
}
predictions = detector.predict(test_data)
print(f"ç®—æ³•äº¤æ˜“æ¦‚ç‡: {predictions['test_session']:.4f}")
```

### 5. æ•°æ®å¤„ç†å’Œåˆ†æ

```python
from data_processing import DataQualityController, InformationEventClassifier
from statistical_analysis import StatisticalAnalyzer, VisualizationSuite

# æ•°æ®è´¨é‡æ§åˆ¶
quality_controller = DataQualityController()
clean_data = quality_controller.data_quality_control(raw_data)

# äº‹ä»¶åˆ†ç±»
classifier = InformationEventClassifier()
classified_events = classifier.classify_information_events(events_list)

# ç»Ÿè®¡åˆ†æ
analyzer = StatisticalAnalyzer()
regression_results = analyzer.regression_analysis(
    data, 'discovery_speed', 
    ['complexity_score', 'algo_trading_intensity']
)

# å¯è§†åŒ–
visualizer = VisualizationSuite()
visualizer.plot_main_results(regression_results)
```

## ğŸ“Š æ ¸å¿ƒç®—æ³•è¯´æ˜

### 1. ä¿¡æ¯å¤æ‚åº¦æµ‹é‡

- **Kolmogorovå¤æ‚åº¦**ï¼šä½¿ç”¨å¤šç§å‹ç¼©ç®—æ³•ï¼ˆgzip, bz2, LZMAç­‰ï¼‰çš„åŠ æƒå¹³å‡
- **è®¡ç®—å¤æ‚åº¦**ï¼šåŸºäºä¿¡æ¯ç±»å‹è‡ªåŠ¨åˆ†ç±»ï¼Œä»O(1)åˆ°O(2^n)
- **é€»è¾‘æ·±åº¦**ï¼šé€šè¿‡ä¾èµ–å›¾åˆ†æè®¡ç®—æœ€é•¿å¤„ç†è·¯å¾„

### 2. å¤æ‚åº¦æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶

```python
# æ ¸å¿ƒå…¬å¼
attention_weights = softmax(QK^T / sqrt(d_k) - Î»C)
```

å…¶ä¸­Cæ˜¯å¤æ‚åº¦æƒ©ç½šçŸ©é˜µï¼ŒÎ»æ˜¯æƒ©ç½šå¼ºåº¦å‚æ•°ã€‚

### 3. ä»·æ ¼å‘ç°æŒ‡æ ‡

- **å‘ç°é€Ÿåº¦**ï¼š90%ä»·æ ¼è°ƒæ•´å®Œæˆçš„æ—¶é—´
- **å‘ç°æ•ˆç‡**ï¼šç¬¬ä¸€å¤©è°ƒæ•´å æ€»è°ƒæ•´çš„æ¯”ä¾‹
- **è°ƒæ•´è´¨é‡**ï¼šä»·æ ¼è°ƒæ•´è¿‡ç¨‹çš„å¹³æ»‘åº¦

## ğŸ§ª å®éªŒç»“æœ

### ä¸»è¦å‘ç°

1. **å¤æ‚åº¦æ•ˆåº”**ï¼šä¿¡æ¯å¤æ‚åº¦æ¯å¢åŠ 1ä¸ªæ ‡å‡†å·®ï¼Œä»·æ ¼å‘ç°å»¶è¿Ÿå¢åŠ 23.4%
2. **ç®—æ³•äº¤æ˜“ç¼“è§£**ï¼šç®—æ³•äº¤æ˜“å°†é«˜å¤æ‚åº¦ä¿¡æ¯çš„å¤„ç†å»¶è¿Ÿå‡å°‘67%
3. **æ¨¡å‹æ€§èƒ½**ï¼šå¤æ‚åº¦æ„ŸçŸ¥æ¨¡å‹çš„RÂ²è¾¾åˆ°0.442ï¼Œæ˜¾è‘—ä¼˜äºåŸºå‡†æ¨¡å‹

### æ¨¡å‹æ€§èƒ½å¯¹æ¯”

| æ¨¡å‹ | RÂ² | MSE | MAE |
|------|----|----|-----|
| çº¿æ€§å›å½’ | 0.123 | 0.245 | 0.387 |
| éšæœºæ£®æ— | 0.291 | 0.198 | 0.312 |
| XGBoost | 0.324 | 0.189 | 0.298 |
| **å¤æ‚åº¦æ„ŸçŸ¥æ¨¡å‹** | **0.442** | **0.156** | **0.267** |

## ğŸ“ ä½¿ç”¨æ³¨æ„äº‹é¡¹

1. **æ•°æ®æ ¼å¼**ï¼šç¡®ä¿è¾“å…¥æ•°æ®æ ¼å¼æ­£ç¡®ï¼Œç‰¹åˆ«æ˜¯æ—¶é—´æˆ³å’Œæ•°å€¼å­—æ®µ
2. **å†…å­˜ä½¿ç”¨**ï¼šå¤§è§„æ¨¡æ•°æ®å¤„ç†æ—¶æ³¨æ„å†…å­˜ç®¡ç†
3. **GPUæ”¯æŒ**ï¼šç¥ç»ç½‘ç»œæ¨¡å‹æ”¯æŒGPUåŠ é€Ÿï¼Œå»ºè®®ä½¿ç”¨CUDA
4. **å‚æ•°è°ƒä¼˜**ï¼šæ ¹æ®å…·ä½“æ•°æ®ç‰¹å¾è°ƒæ•´æ¨¡å‹è¶…å‚æ•°

## ğŸ”§ é…ç½®å‚æ•°

### æ¨¡å‹é…ç½®

```python
model_config = {
    'vocab_size': 10000,     # è¯æ±‡è¡¨å¤§å°
    'd_model': 256,          # æ¨¡å‹ç»´åº¦
    'n_heads': 8,            # æ³¨æ„åŠ›å¤´æ•°
    'num_layers': 6,         # å±‚æ•°
    'dropout': 0.1           # Dropoutç‡
}
```

### å¤æ‚åº¦è®¡ç®—é…ç½®

```python
complexity_config = {
    'missing_threshold': 0.1,        # ç¼ºå¤±å€¼é˜ˆå€¼
    'outlier_method': 'modified_tukey',  # å¼‚å¸¸å€¼æ£€æµ‹æ–¹æ³•
    'compression_algorithms': ['gzip', 'bz2', 'lzma']  # å‹ç¼©ç®—æ³•
}
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›é¡¹ç›®ã€‚

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ“ è”ç³»æ–¹å¼

- **ä½œè€…**ï¼šYimin Du, Guolin Tang
- **é‚®ç®±**ï¼šsa613403@mail.ustc.edu.cn, guolin_tang@163.com

## ğŸ“š å¼•ç”¨

å¦‚æœä½¿ç”¨æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@article{du2024computational,
  title={Computational Complexity and Market Efficiency: A Machine Learning Approach to Information Processing in Financial Markets},
  author={Du, Yimin and Tang, Guolin},
  journal={IEEE Conference on Computational Intelligence for Financial Engineering and Economics},
  year={2024}
}
```

---

**æ³¨æ„**ï¼šæœ¬é¡¹ç›®ä»…ç”¨äºå­¦æœ¯ç ”ç©¶ç›®çš„ï¼Œå®é™…åº”ç”¨å‰è¯·è¿›è¡Œå……åˆ†çš„é£é™©è¯„ä¼°ã€‚
